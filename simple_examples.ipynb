{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, './src/')\n",
    "from target import NN_bernoulli\n",
    "from kernels import HMC_our, Reverse_kernel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Encoder' - simple matrix\n",
    "class Encoder_h(nn.Module):\n",
    "    def __init__(self, L, z_dim, device='cpu'):\n",
    "        super(Encoder_h, self).__init__()\n",
    "        self.L = L\n",
    "        self.z_dim = z_dim\n",
    "        self.mu = nn.Linear(in_features=self.L, out_features=self.z_dim, bias=False)\n",
    "        self.h = nn.Linear(in_features=self.L, out_features=self.z_dim)\n",
    "    def forward(self, x):\n",
    "        return self.mu(x), self.h(x)\n",
    "    \n",
    "# 'Encoder' - simple matrix\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, L, z_dim, device='cpu'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.L = L\n",
    "        self.z_dim = z_dim\n",
    "        self.mu = nn.Linear(in_features=self.L, out_features=self.z_dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.mu(x)\n",
    "    \n",
    "# 'Decoder' - simple matrix, return logits\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, L, z_dim, device='cpu'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.L = L\n",
    "        self.z_dim = z_dim\n",
    "        self.W = nn.Linear(in_features=self.z_dim, out_features=self.L, bias=False)\n",
    "    def forward(self, z):\n",
    "        return [self.W(z)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 2\n",
    "z_dim = 2\n",
    "N = 100\n",
    "device = \"cpu\"#\"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "args = dotdict({})\n",
    "args.K = 2\n",
    "args.N = 2\n",
    "args.z_dim = z_dim\n",
    "args.torchType = torch.float32\n",
    "args.device = device\n",
    "args.learnable_reverse = True\n",
    "args.num_epoches = 5000\n",
    "args.train_batch_size = 50\n",
    "args.amortize = False\n",
    "args.gamma = 0.1 ## Stepsize\n",
    "args.alpha = 0.5  ## For partial momentum refresh\n",
    "args.train_only_inference_period = 10\n",
    "args.train_only_inference_cutoff = 5\n",
    "args.hoffman_idea = True\n",
    "args.separate_params = True\n",
    "args.use_barker = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.learnable_reverse:\n",
    "    enc = Encoder_h(L=L, z_dim=z_dim, device=device).to(device)\n",
    "else:\n",
    "    enc = Encoder(L=L, z_dim=z_dim, device=device).to(device)\n",
    "dec = Decoder(L=L, z_dim=z_dim, device=device).to(device)\n",
    "reverse_kernel = Reverse_kernel(args).to(device)\n",
    "target = NN_bernoulli({}, dec, device).to(device)\n",
    "transitions = nn.ModuleList([HMC_our(kwargs=args).to(args.device) for _ in range(args['K'])])\n",
    "\n",
    "std_normal = torch.distributions.Normal(loc=torch.tensor(0., device=device),\n",
    "                                                scale=torch.tensor(1., device=device))\n",
    "args.std_normal = std_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True decoder matrix\n",
      "tensor([[-0.9196,  1.2161],\n",
      "        [ 1.1737, -0.9498]])\n",
      "---------------------------------------------------------------------------\n",
      "Generated data example:\n",
      "tensor([[1., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "true_theta = std_normal.sample((z_dim, L))# + 5\n",
    "print('True decoder matrix')\n",
    "print(true_theta)\n",
    "print('-' * 75)\n",
    "data_probs = torch.sigmoid(std_normal.sample((N, z_dim)) @ true_theta)\n",
    "# data_probs = torch.sigmoid(torch.ones((N, z_dim), device=device) @ true_theta)\n",
    "data = torch.distributions.Bernoulli(probs=data_probs).sample()\n",
    "print('Generated data example:')\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data, batch_size=args.train_batch_size, shuffle=True)\n",
    "\n",
    "reverse_params = list([])\n",
    "if args.learnable_reverse:\n",
    "    reverse_params = list(reverse_kernel.parameters())\n",
    "\n",
    "if args.separate_params:\n",
    "    params = list(enc.parameters()) + list(reverse_kernel.parameters()) + list(transitions.parameters())\n",
    "    optimizer = torch.optim.Adam(params=target.parameters())\n",
    "    optimizer_inference = torch.optim.Adam(params=params)\n",
    "else:\n",
    "    params = list(enc.parameters()) + list(target.parameters()) + list(transitions.parameters()) + reverse_params\n",
    "    optimizer = torch.optim.Adam(params=params)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 200, 300, 400], gamma=0.5) #torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2717, -0.6099],\n",
       "        [-0.5089, -0.2191]], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.mu.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(z_new, p_new, u, p_old, x, sum_log_alpha, sum_log_jac, sum_log_sigma=0., mu=None, all_directions=None, h=None):\n",
    "    if args.learnable_reverse:\n",
    "        log_r = reverse_kernel(z_fin=z_new.detach(), h=h.detach(), a=all_directions)\n",
    "        log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jac - sum_log_sigma + sum_log_alpha\n",
    "    else:\n",
    "        log_r = -args.K * torch.tensor(np.log(2.), device=device)\n",
    "        log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jac - sum_log_sigma + sum_log_alpha\n",
    "        \n",
    "    log_p = target.get_logdensity(z=z_new, x=x, args=args) + args.std_normal.log_prob(p_new.sum(1))\n",
    "    elbo_full = log_p + log_r - log_m\n",
    "    grad_elbo = torch.mean(elbo_full + elbo_full.detach() * sum_log_alpha)\n",
    "    return elbo_full, grad_elbo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/5000 [00:00<01:22, 60.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.56 and for +1: 0.44\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.48 and for +1: 0.52\n",
      "obj_1: tensor(1.3110, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-7.4289, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 512/5000 [00:07<01:03, 70.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.32 and for +1: 0.68\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.56 and for +1: 0.44\n",
      "obj_1: tensor(0.4931, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-7.1133, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1007/5000 [00:14<00:56, 70.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.48 and for +1: 0.52\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.52 and for +1: 0.48\n",
      "obj_1: tensor(0.3981, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-7.4428, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1513/5000 [00:21<00:49, 70.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.52 and for +1: 0.48\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.54 and for +1: 0.46\n",
      "obj_1: tensor(0.2315, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-6.9668, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2012/5000 [00:28<00:39, 74.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.5 and for +1: 0.5\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.54 and for +1: 0.46\n",
      "obj_1: tensor(0.2556, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-6.9195, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2508/5000 [00:34<00:33, 75.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.64 and for +1: 0.36\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.42 and for +1: 0.58\n",
      "obj_1: tensor(0.2367, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-7.2249, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3012/5000 [00:41<00:26, 75.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.5 and for +1: 0.5\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.6 and for +1: 0.4\n",
      "obj_1: tensor(0.2640, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-6.9882, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3508/5000 [00:48<00:19, 75.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.5 and for +1: 0.5\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.52 and for +1: 0.48\n",
      "obj_1: tensor(0.2268, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-6.8993, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4012/5000 [00:55<00:13, 74.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.56 and for +1: 0.44\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.42 and for +1: 0.58\n",
      "obj_1: tensor(0.1106, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-6.8914, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4508/5000 [01:01<00:06, 70.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/2 and on k = 1 we have for  0: 0.56 and for +1: 0.44\n",
      "On batch number 1/2 and on k = 2 we have for  0: 0.42 and for +1: 0.58\n",
      "obj_1: tensor(0.1705, grad_fn=<MeanBackward0>)\n",
      "obj_2: tensor(-6.8818, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:08<00:00, 72.80it/s]\n"
     ]
    }
   ],
   "source": [
    "print_info_ = 500\n",
    "\n",
    "for ep in tqdm(range(args.num_epoches)): # cycle over epoches\n",
    "    for b_num, batch_train in enumerate(dataloader): # cycle over batches\n",
    "        if args.learnable_reverse:\n",
    "            mu, h = enc(batch_train) # sample mu and sigma from encoder\n",
    "        else:\n",
    "            mu = enc(batch_train) # sample mu and sigma from encoder\n",
    "            h = None\n",
    "        u = args.std_normal.sample(mu.shape) # sample random tensor for reparametrization trick\n",
    "        z = mu + u # reperametrization trick\n",
    "\n",
    "        p_old = args.std_normal.sample(z.shape)\n",
    "        cond_vectors = [args.std_normal.sample(p_old.shape) for _ in range(args.K)]\n",
    "\n",
    "        sum_log_alpha = torch.zeros(mu.shape[0], dtype=args.torchType, device=args.device) # for grad log alpha accumulation\n",
    "        sum_log_jacobian = torch.zeros(mu.shape[0], dtype=args.torchType, device=args.device) # for log_jacobian accumulation\n",
    "        p = p_old\n",
    "        if args.learnable_reverse:\n",
    "            all_directions = torch.tensor([], device=args.device)\n",
    "        else:\n",
    "            all_directions = None\n",
    "        for k in range(args.K):\n",
    "            # sample alpha - transition probabilities \n",
    "            if args.amortize:\n",
    "#                     pdb.set_trace()\n",
    "                z, p, log_jac, current_log_alphas, directions, _ = transitions.make_transition(q_old=z, x=batch_train,\n",
    "                                                    p_old=p, k=cond_vectors[k], target_distr=target, args=args)\n",
    "            else:\n",
    "                z, p, log_jac, current_log_alphas, directions, _ = transitions[k].make_transition(q_old=z, x=batch_train,\n",
    "                                                                    p_old=p, k=cond_vectors[k], target_distr=target, args=args) # sample a_i -- directions\n",
    "            if ep  % print_info_ == 0 and b_num % (100 * print_info_) == 0:\n",
    "                print('On batch number {}/{} and on k = {} we have for  0: {} and for +1: {}'.format(b_num + 1,\n",
    "                                                                        data.shape[0] // args['train_batch_size'],\n",
    "                                                                           k + 1,\n",
    "                                                    (directions==0.).to(float).mean(),\n",
    "                                                                    (directions==1.).to(float).mean()))\n",
    "                if args.amortize:\n",
    "                    print('Stepsize {}'.format(np.exp(transitions.gamma.cpu().detach().item())))\n",
    "                    print('Autoregression coeff {}'.format(torch.sigmoid(transitions.alpha_logit).cpu().detach().item()))\n",
    "            if args.learnable_reverse:\n",
    "                all_directions = torch.cat([all_directions, directions.view(-1, 1)], dim=1)\n",
    "            # Accumulate alphas\n",
    "            sum_log_alpha = sum_log_alpha + current_log_alphas\n",
    "            sum_log_jacobian = sum_log_jacobian + log_jac  # refresh log jacobian\n",
    "        ##############################################\n",
    "        if args.hoffman_idea:\n",
    "            if args.learnable_reverse:\n",
    "                log_r = reverse_kernel(z_fin=z.detach(), h=h.detach(), a=all_directions)\n",
    "                log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jacobian + sum_log_alpha\n",
    "            else:\n",
    "                log_r = -args.K * torch_log_2\n",
    "                log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jacobian + sum_log_alpha\n",
    "            log_p = target.get_logdensity(z=z, x=batch_train, args=args) + args.std_normal.log_prob(p.sum(1))\n",
    "            elbo_full = log_p + log_r - log_m\n",
    "    #                 pdb.set_trace()\n",
    "            ### Gradient of the first objective:\n",
    "#             target.eval()\n",
    "            obj_1 = torch.mean(elbo_full + elbo_full.detach() * sum_log_alpha)\n",
    "            (-obj_1).backward(retain_graph=True)\n",
    "            optimizer_inference.step()\n",
    "            optimizer_inference.zero_grad()\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            ### Gradient of the second objective:\n",
    "#             target.train()\n",
    "            log_p = target.get_logdensity(z=z.detach(), x=batch_train, args=args) + args.std_normal.log_prob(p.detach()).sum(1)\n",
    "            obj_2 = torch.mean(log_p)\n",
    "            (-obj_2).backward()\n",
    "            optimizer.step()\n",
    "            optimizer_inference.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "        else:\n",
    "            elbo_full, grad_elbo = compute_loss(z_new=z, p_new=p, u=u, p_old=p_old, x=batch_train, sum_log_alpha=sum_log_alpha,\n",
    "                                                sum_log_jac=sum_log_jacobian, mu=mu,\n",
    "                                                all_directions=all_directions, h=h)\n",
    "            (-grad_elbo).backward()\n",
    "\n",
    "                \n",
    "        if args.separate_params: # if we separate params of inference part and generation part\n",
    "            optimizer_inference.step() # we always perform step for inference part\n",
    "            if ep % args.train_only_inference_period > args.train_only_inference_cutoff: # but sometimes for gen\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_inference.zero_grad()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "            \n",
    "        if ep  % print_info_ == 0 and b_num % (100 * print_info_) == 0:\n",
    "            if args.hoffman_idea:\n",
    "                print('obj_1:', obj_1)\n",
    "                print('obj_2:', obj_2)\n",
    "            else:\n",
    "                print('elbo:', elbo_full.mean().cpu().detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0561,  0.0124],\n",
       "        [-0.4709,  0.4122]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.decoder.W.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.decoder.W.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9196,  1.2161],\n",
      "        [ 1.1737, -0.9498]])\n"
     ]
    }
   ],
   "source": [
    "print(true_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0286,  0.0149],\n",
       "        [-0.4285,  0.3998]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.mu.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Encoder' - simple matrix\n",
    "class Encoder_vae(nn.Module):\n",
    "    def __init__(self, L, z_dim, device='cpu'):\n",
    "        super(Encoder_vae, self).__init__()\n",
    "        self.L = L\n",
    "        self.z_dim = z_dim\n",
    "        self.mu = nn.Linear(in_features=self.L, out_features=self.z_dim, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.mu(x)\n",
    "    \n",
    "class Decoder_vae(nn.Module):\n",
    "    def __init__(self, L, z_dim, device='cpu'):\n",
    "        super(Decoder_vae, self).__init__()\n",
    "        self.L = L\n",
    "        self.z_dim = z_dim\n",
    "        self.d = nn.Linear(in_features=self.z_dim, out_features=self.L, bias=False)\n",
    "    def forward(self, x):\n",
    "        return self.d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder_vae(L=L, z_dim=z_dim, device=device).to(device)\n",
    "dec = Decoder_vae(L=L, z_dim=z_dim, device=device).to(device)\n",
    "\n",
    "std_normal = torch.distributions.Normal(loc=torch.tensor(0., device=device),\n",
    "                                                scale=torch.tensor(1., device=device))\n",
    "args.std_normal = std_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(enc.parameters()) + list(dec.parameters())\n",
    "optimizer = torch.optim.Adam(params=params)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 200, 300, 400], gamma=0.75) #torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=0, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<05:57, 13.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.7558897733688354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 104/5000 [00:05<03:57, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3855681419372559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 203/5000 [00:09<03:53, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.38618803024292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 305/5000 [00:14<03:48, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3864556550979614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 404/5000 [00:19<03:44, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.386893391609192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 503/5000 [00:24<03:38, 20.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.386488676071167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 605/5000 [00:29<03:33, 20.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3867928981781006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 704/5000 [00:34<03:28, 20.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3858445882797241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 803/5000 [00:39<03:23, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3866851329803467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 905/5000 [00:44<03:18, 20.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3862485885620117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1004/5000 [00:48<03:14, 20.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3864082098007202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1103/5000 [00:53<03:08, 20.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.385992169380188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1205/5000 [00:58<03:04, 20.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3865265846252441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1304/5000 [01:03<03:00, 20.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3859598636627197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1403/5000 [01:08<02:55, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3872487545013428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1505/5000 [01:13<02:50, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3858733177185059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1604/5000 [01:18<02:45, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3857648372650146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1703/5000 [01:22<02:41, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.387223243713379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1805/5000 [01:27<02:36, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.386448621749878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1904/5000 [01:32<02:31, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3855845928192139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2003/5000 [01:37<02:26, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3861188888549805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2105/5000 [01:42<02:20, 20.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3872483968734741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2204/5000 [01:47<02:16, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3860719203948975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2303/5000 [01:52<02:11, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3861651420593262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2405/5000 [01:57<02:06, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3858051300048828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2504/5000 [02:02<02:01, 20.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3854498863220215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2603/5000 [02:06<01:57, 20.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3863214254379272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2705/5000 [02:11<01:52, 20.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3867474794387817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2804/5000 [02:16<01:47, 20.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3869109153747559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2903/5000 [02:21<01:42, 20.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3860423564910889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3005/5000 [02:26<01:37, 20.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3863308429718018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 3104/5000 [02:31<01:32, 20.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3863017559051514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 3203/5000 [02:36<01:27, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3859273195266724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3305/5000 [02:41<01:22, 20.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.386637806892395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3404/5000 [02:46<01:18, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3862502574920654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3503/5000 [02:50<01:13, 20.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3869497776031494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3605/5000 [02:55<01:08, 20.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.386596441268921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3704/5000 [03:00<01:02, 20.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3868342638015747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 3803/5000 [03:05<00:57, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3865556716918945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3905/5000 [03:10<00:52, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3861229419708252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4004/5000 [03:15<00:48, 20.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3862134218215942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4103/5000 [03:19<00:43, 20.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3863948583602905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4205/5000 [03:24<00:38, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.386583685874939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4304/5000 [03:29<00:33, 20.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3863840103149414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4403/5000 [03:34<00:28, 20.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.387058973312378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4505/5000 [03:39<00:23, 20.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3871320486068726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4604/5000 [03:44<00:19, 20.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3855648040771484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4703/5000 [03:48<00:14, 20.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3863588571548462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4805/5000 [03:53<00:09, 20.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.3861969709396362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4904/5000 [03:58<00:04, 20.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elbo: -1.387112021446228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:03<00:00, 20.55it/s]\n"
     ]
    }
   ],
   "source": [
    "print_info_ = 100\n",
    "# with torch.autograd.detect_anomaly():\n",
    "for ep in tqdm(range(args.num_epoches)): # cycle over epoches\n",
    "    for b_num, batch_train in enumerate(dataloader): # cycle over batches\n",
    "#         pdb.set_trace()\n",
    "        mu = enc(batch_train) # sample mu and sigma from encoder\n",
    "        u = args.std_normal.sample(mu.shape) # sample random tensor for reparametrization trick\n",
    "        z = mu + u # reperametrization trick\n",
    "        batch_recovered = dec(z)\n",
    "        probs = torch.sigmoid(batch_recovered)\n",
    "        \n",
    "        log_likelihood = torch.distributions.Bernoulli(probs=probs).log_prob(batch_train).sum(1)\n",
    "        log_prior = std_normal.log_prob(z).sum(1)\n",
    "        log_q = std_normal.log_prob(u).sum(1)\n",
    "        \n",
    "        elbo = torch.mean(log_likelihood + log_prior - log_q)\n",
    "        (-elbo).backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "    if ep % print_info_ == 0:\n",
    "        print('elbo:', elbo.cpu().detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0039, -0.0011],\n",
       "        [-0.0083, -0.0068]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.d.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec.d.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6969, 0.2562],\n",
      "        [0.7179, 0.3912]])\n"
     ]
    }
   ],
   "source": [
    "print(true_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b_num, batch_train in enumerate(dataloader): # cycle over batches\n",
    "    mu = enc(batch_train) # sample mu and sigma from encoder\n",
    "    u = args.std_normal.sample(mu.shape) # sample random tensor for reparametrization trick\n",
    "    z = mu + u # reperametrization trick\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.Bernoulli(probs=torch.sigmoid(dec(z[:10]))).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Condatorch",
   "language": "python",
   "name": "condatorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
