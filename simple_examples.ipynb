{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, './src/')\n",
    "from target import NN_bernoulli\n",
    "from kernels import HMC_our, Reverse_kernel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Encoder' - simple matrix\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, L, z_dim, device='cpu'):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.L = L\n",
    "        self.z_dim = z_dim\n",
    "        self.mu = nn.Linear(in_features=self.L, out_features=self.z_dim)\n",
    "        self.sigma = nn.Linear(in_features=self.L, out_features=self.z_dim)\n",
    "        self.h = nn.Linear(in_features=self.L, out_features=self.z_dim)\n",
    "    def forward(self, x):\n",
    "        return self.mu(x), nn.functional.softplus(self.sigma(x)), self.h(x)\n",
    "    \n",
    "# 'Decoder' - simple matrix, return logits\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, L, z_dim, device='cpu'):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.L = L\n",
    "        self.z_dim = z_dim\n",
    "        self.W = nn.Linear(in_features=self.z_dim, out_features=self.L, bias=False)\n",
    "    def forward(self, z):\n",
    "        return [self.W(z)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 2\n",
    "z_dim = 2\n",
    "N = 10000\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "args = dotdict({})\n",
    "args.K = 1\n",
    "args.N = 1\n",
    "args.z_dim = z_dim\n",
    "args.torchType = torch.float32\n",
    "args.device = device\n",
    "args.learnable_reverse = True\n",
    "args.num_epoches = 500\n",
    "args.train_batch_size = 100\n",
    "args.amortize = False\n",
    "args.gamma = 0.1 ## Stepsize\n",
    "args.alpha = 0.5  ## For partial momentum refresh\n",
    "args.train_only_inference_period = 10\n",
    "args.train_only_inference_cutoff = 5\n",
    "args.hoffman_idea = True\n",
    "args.separate_params = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(L=L, z_dim=z_dim, device=device).to(device)\n",
    "dec = Decoder(L=L, z_dim=z_dim, device=device).to(device)\n",
    "reverse_kernel = Reverse_kernel(args)\n",
    "target = NN_bernoulli({}, dec, device).to(device)\n",
    "transitions = nn.ModuleList([HMC_our(kwargs=args).to(args.device) for _ in range(args['K'])])\n",
    "\n",
    "std_normal = torch.distributions.Normal(loc=torch.tensor(0., device=device),\n",
    "                                                scale=torch.tensor(1., device=device))\n",
    "args.std_normal = std_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True decoder matrix\n",
      "tensor([[ 0.1476,  0.7996],\n",
      "        [-0.9377, -1.8887]])\n",
      "---------------------------------------------------------------------------\n",
      "Generated data example:\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "true_theta = std_normal.sample((z_dim, L))\n",
    "print('True decoder matrix')\n",
    "print(true_theta)\n",
    "print('-' * 75)\n",
    "data_logits = std_normal.sample((N, z_dim)) @ true_theta\n",
    "data = torch.distributions.Bernoulli(logits=data_logits).sample()\n",
    "print('Generated data example:')\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(data, batch_size=args.train_batch_size, shuffle=True)\n",
    "\n",
    "params = list(enc.parameters()) + list(reverse_kernel.parameters())\n",
    "optimizer = torch.optim.Adam(params=target.parameters())\n",
    "optimizer_inference = torch.optim.Adam(params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(z_new, p_new, u, p_old, x, sum_log_alpha, sum_log_jac, sum_log_sigma, mu=None, all_directions=None, h=None):\n",
    "    if args.learnable_reverse:\n",
    "        log_r = reverse_kernel(z_fin=z_new.detach(), mu=mu.detach(), a=all_directions)\n",
    "        log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jac - sum_log_sigma + sum_log_alpha\n",
    "    else:\n",
    "        log_r = 0 #-args.K * torch_log_2\n",
    "        log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jac - sum_log_sigma # + sum_log_alpha\n",
    "        \n",
    "    log_p = target.get_logdensity(z=z_new, x=x, prior=get_prior, args=args) + args.std_normal.log_prob(p_new.sum(1))\n",
    "    elbo_full = log_p + log_r - log_m\n",
    "    grad_elbo = torch.mean(elbo_full + elbo_full.detach() * sum_log_alpha)\n",
    "    return elbo_full, grad_elbo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m10\u001b[00m)<module>()\n",
      "-> mu, sigma, h = enc(batch_train) # sample mu and sigma from encoder\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m11\u001b[00m)<module>()\n",
      "-> u = args.std_normal.sample(mu.shape) # sample random tensor for reparametrization trick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m12\u001b[00m)<module>()\n",
      "-> z = mu + sigma * u # reperametrization trick\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m13\u001b[00m)<module>()\n",
      "-> sum_log_sigma = torch.sum(torch.log(sigma), 1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  print(h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1809, -0.0150],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.1809, -0.0150],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.4707,  0.0126],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.0026,  0.2459],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.6491, -0.2483],\n",
      "        [ 0.4707,  0.0126]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m15\u001b[00m)<module>()\n",
      "-> p_old = args.std_normal.sample(z.shape)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m16\u001b[00m)<module>()\n",
      "-> cond_vectors = [args.std_normal.sample(p_old.shape) for _ in range(args.K)]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m18\u001b[00m)<module>()\n",
      "-> sum_log_alpha = torch.zeros(mu.shape[0], dtype=args.torchType, device=args.device) # for grad log alpha accumulation\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m19\u001b[00m)<module>()\n",
      "-> sum_log_jacobian = torch.zeros(mu.shape[0], dtype=args.torchType, device=args.device) # for log_jacobian accumulation\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m20\u001b[00m)<module>()\n",
      "-> p = p_old\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m21\u001b[00m)<module>()\n",
      "-> if args.learnable_reverse:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m22\u001b[00m)<module>()\n",
      "-> all_directions = torch.tensor([], device=args.device)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[34;01m17\u001b[39;49;00m  \t\n",
      " \u001b[34;01m18\u001b[39;49;00m  \t        sum_log_alpha = torch.zeros(mu.shape[\u001b[34;01m0\u001b[39;49;00m], dtype=args.torchType, device=args.device) \u001b[30;01m# for grad log alpha accumulation\u001b[39;49;00m\n",
      " \u001b[34;01m19\u001b[39;49;00m  \t        sum_log_jacobian = torch.zeros(mu.shape[\u001b[34;01m0\u001b[39;49;00m], dtype=args.torchType, device=args.device) \u001b[30;01m# for log_jacobian accumulation\u001b[39;49;00m\n",
      " \u001b[34;01m20\u001b[39;49;00m  \t        p = p_old\n",
      " \u001b[34;01m21\u001b[39;49;00m  \t        \u001b[34;01mif\u001b[39;49;00m args.learnable_reverse:\n",
      " \u001b[34;01m22\u001b[39;49;00m  ->\t            all_directions = torch.tensor([], device=args.device)\n",
      " \u001b[34;01m23\u001b[39;49;00m  \t        \u001b[34;01melse\u001b[39;49;00m:\n",
      " \u001b[34;01m24\u001b[39;49;00m  \t            all_directions = \u001b[36;01mNone\u001b[39;49;00m\n",
      " \u001b[34;01m25\u001b[39;49;00m  \t        \u001b[34;01mfor\u001b[39;49;00m k \u001b[35;01min\u001b[39;49;00m \u001b[36;01mrange\u001b[39;49;00m(args.K):\n",
      " \u001b[34;01m26\u001b[39;49;00m  \t            \u001b[30;01m# sample alpha - transition probabilities\u001b[39;49;00m\n",
      " \u001b[34;01m27\u001b[39;49;00m  \t            \u001b[34;01mif\u001b[39;49;00m args.amortize:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m25\u001b[00m)<module>()\n",
      "-> for k in range(args.K):\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m27\u001b[00m)<module>()\n",
      "-> if args.amortize:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m32\u001b[00m)<module>()\n",
      "-> z, p, log_jac, current_log_alphas, directions, _ = transitions[k].make_transition(q_old=z, x=batch_train,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m33\u001b[00m)<module>()\n",
      "-> p_old=p, k=cond_vectors[k], target_distr=target, args=args) # sample a_i -- directions\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m34\u001b[00m)<module>()\n",
      "-> if ep  % print_info_ == 0 and b_num % (100 * print_info_) == 0:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m35\u001b[00m)<module>()\n",
      "-> print('On batch number {}/{} and on k = {} we have for  0: {} and for +1: {}'.format(b_num + 1,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m36\u001b[00m)<module>()\n",
      "-> data.shape[0] // args['train_batch_size'],\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m37\u001b[00m)<module>()\n",
      "-> k + 1,\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m38\u001b[00m)<module>()\n",
      "-> (directions==0.).to(float).mean(),\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001b[34;01m28\u001b[39;49;00m  \t\u001b[30;01m#                     pdb.set_trace()\u001b[39;49;00m\n",
      " \u001b[34;01m29\u001b[39;49;00m  \t                z, p, log_jac, current_log_alphas, directions, _ = transitions.make_transition(q_old=z, x=batch_train,\n",
      " \u001b[34;01m30\u001b[39;49;00m  \t                                                    p_old=p, k=cond_vectors[k], target_distr=target, args=args)\n",
      " \u001b[34;01m31\u001b[39;49;00m  \t            \u001b[34;01melse\u001b[39;49;00m:\n",
      " \u001b[34;01m32\u001b[39;49;00m  \t                z, p, log_jac, current_log_alphas, directions, _ = transitions[k].make_transition(q_old=z, x=batch_train,\n",
      " \u001b[34;01m33\u001b[39;49;00m  \t                                                                    p_old=p, k=cond_vectors[k], target_distr=target, args=args) \u001b[30;01m# sample a_i -- directions\u001b[39;49;00m\n",
      " \u001b[34;01m34\u001b[39;49;00m  \t            \u001b[34;01mif\u001b[39;49;00m ep  % print_info_ == \u001b[34;01m0\u001b[39;49;00m \u001b[35;01mand\u001b[39;49;00m b_num % (\u001b[34;01m100\u001b[39;49;00m * print_info_) == \u001b[34;01m0\u001b[39;49;00m:\n",
      " \u001b[34;01m35\u001b[39;49;00m  \t                \u001b[34;01mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mOn batch number {}/{} and on k = {} we have for  0: {} and for +1: {}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(b_num + \u001b[34;01m1\u001b[39;49;00m,\n",
      " \u001b[34;01m36\u001b[39;49;00m  \t                                                                        data.shape[\u001b[34;01m0\u001b[39;49;00m] // args[\u001b[33m'\u001b[39;49;00m\u001b[33mtrain_batch_size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m],\n",
      " \u001b[34;01m37\u001b[39;49;00m  \t                                                                           k + \u001b[34;01m1\u001b[39;49;00m,\n",
      " \u001b[34;01m38\u001b[39;49;00m  ->\t                                                    (directions==\u001b[34;01m0.\u001b[39;49;00m).to(\u001b[36;01mfloat\u001b[39;49;00m).mean(),\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m39\u001b[00m)<module>()\n",
      "-> (directions==1.).to(float).mean()))\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch number 1/100 and on k = 1 we have for  0: 0.0 and for +1: 1.0\n",
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m40\u001b[00m)<module>()\n",
      "-> if args.amortize:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m43\u001b[00m)<module>()\n",
      "-> if args.learnable_reverse:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27] > \u001b[33;01m<ipython-input-9-8352655101b0>\u001b[00m(\u001b[36;01m44\u001b[00m)<module>()\n",
      "-> all_directions = torch.cat([all_directions, directions.view(-1, 1)], dim=1)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb++)  q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8352655101b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Autoregression coeff {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_logit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearnable_reverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mall_directions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_directions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;31m# Accumulate alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0msum_log_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_log_alpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_log_alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-8352655101b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Autoregression coeff {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha_logit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearnable_reverse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0mall_directions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mall_directions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;31m# Accumulate alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0msum_log_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum_log_alpha\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_log_alphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_elbo = -float(\"inf\")\n",
    "current_tolerance = 0\n",
    "print_info_ = 10\n",
    "# with torch.autograd.detect_anomaly():\n",
    "for ep in tqdm(range(args.num_epoches)): # cycle over epoches\n",
    "    for b_num, batch_train in enumerate(dataloader): # cycle over batches\n",
    "        plt.close()        \n",
    "        pdb.set_trace()\n",
    "\n",
    "        mu, sigma, h = enc(batch_train) # sample mu and sigma from encoder\n",
    "        u = args.std_normal.sample(mu.shape) # sample random tensor for reparametrization trick\n",
    "        z = mu + sigma * u # reperametrization trick\n",
    "        sum_log_sigma = torch.sum(torch.log(sigma), 1)\n",
    "\n",
    "        p_old = args.std_normal.sample(z.shape)\n",
    "        cond_vectors = [args.std_normal.sample(p_old.shape) for _ in range(args.K)]\n",
    "\n",
    "        sum_log_alpha = torch.zeros(mu.shape[0], dtype=args.torchType, device=args.device) # for grad log alpha accumulation\n",
    "        sum_log_jacobian = torch.zeros(mu.shape[0], dtype=args.torchType, device=args.device) # for log_jacobian accumulation\n",
    "        p = p_old\n",
    "        if args.learnable_reverse:\n",
    "            all_directions = torch.tensor([], device=args.device)\n",
    "        else:\n",
    "            all_directions = None\n",
    "        for k in range(args.K):\n",
    "            # sample alpha - transition probabilities \n",
    "            if args.amortize:\n",
    "#                     pdb.set_trace()\n",
    "                z, p, log_jac, current_log_alphas, directions, _ = transitions.make_transition(q_old=z, x=batch_train,\n",
    "                                                    p_old=p, k=cond_vectors[k], target_distr=target, args=args)\n",
    "            else:\n",
    "                z, p, log_jac, current_log_alphas, directions, _ = transitions[k].make_transition(q_old=z, x=batch_train,\n",
    "                                                                    p_old=p, k=cond_vectors[k], target_distr=target, args=args) # sample a_i -- directions\n",
    "            if ep  % print_info_ == 0 and b_num % (100 * print_info_) == 0:\n",
    "                print('On batch number {}/{} and on k = {} we have for  0: {} and for +1: {}'.format(b_num + 1,\n",
    "                                                                        data.shape[0] // args['train_batch_size'],\n",
    "                                                                           k + 1,\n",
    "                                                    (directions==0.).to(float).mean(),\n",
    "                                                                    (directions==1.).to(float).mean()))\n",
    "                if args.amortize:\n",
    "                    print('Stepsize {}'.format(np.exp(transitions.gamma.cpu().detach().item())))\n",
    "                    print('Autoregression coeff {}'.format(torch.sigmoid(transitions.alpha_logit).cpu().detach().item()))\n",
    "            if args.learnable_reverse:\n",
    "                all_directions = torch.cat([all_directions, directions.view(-1, 1)], dim=1)\n",
    "            # Accumulate alphas\n",
    "            sum_log_alpha = sum_log_alpha + current_log_alphas\n",
    "            sum_log_jacobian = sum_log_jacobian + log_jac  # refresh log jacobian\n",
    "        ##############################################\n",
    "        if args.hoffman_idea:\n",
    "            if args.learnable_reverse:\n",
    "                log_r = reverse_kernel(z_fin=z.detach(), h=h.detach(), a=all_directions)\n",
    "                log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jacobian - sum_log_sigma + sum_log_alpha\n",
    "            else:\n",
    "                log_r = 0 #-args.K * torch_log_2\n",
    "                log_m = args.std_normal.log_prob(u).sum(1) + args.std_normal.log_prob(p_old).sum(1) - sum_log_jacobian - sum_log_sigma # + sum_log_alpha\n",
    "            log_p = target.get_logdensity(z=z, x=batch_train, args=args) + args.std_normal.log_prob(p.sum(1))\n",
    "            elbo_full = log_p + log_r - log_m\n",
    "    #                 pdb.set_trace()\n",
    "            ### Gradient of the first objective:\n",
    "            target.eval()\n",
    "            obj_1 = torch.mean(elbo_full + elbo_full.detach() * sum_log_alpha)\n",
    "            (-obj_1).backward(retain_graph=True)\n",
    "            optimizer_inference.step()\n",
    "            optimizer_inference.zero_grad()\n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            ### Gradient of the second objective:\n",
    "            target.train()\n",
    "            log_p = target.get_logdensity(z=z.detach(), x=batch_train, args=args) + args.std_normal.log_prob(p.detach()).sum(1)\n",
    "            elbo_full = log_p # - log_m\n",
    "            obj_2 = torch.mean(elbo_full + elbo_full.detach() * sum_log_alpha)\n",
    "            (-obj_2).backward()\n",
    "            optimizer.step()\n",
    "            optimizer_inference.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            ###########################################################\n",
    "        else:\n",
    "            elbo_full, grad_elbo = compute_loss(z_new=z, p_new=p, u=u, p_old=p_old, x=batch_train, sum_log_alpha=sum_log_alpha,\n",
    "                                                sum_log_jac=sum_log_jacobian, sum_log_sigma=sum_log_sigma, mu=mu,\n",
    "                                                all_directions=all_directions, args=args, h=h)\n",
    "            (-grad_elbo).backward()\n",
    "\n",
    "                \n",
    "        if args.separate_params: # if we separate params of inference part and generation part\n",
    "            optimizer_inference.step() # we always perform step for inference part\n",
    "            if ep % args.train_only_inference_period > args.train_only_inference_cutoff: # but sometimes for gen\n",
    "                optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            optimizer_inference.zero_grad()\n",
    "        else:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        if ep  % print_info_ == 0 and b_num % (100 * print_info_) == 0:\n",
    "            print('obj_1:', obj_1)\n",
    "            print('obj_2:', obj_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1764,  0.1606],\n",
       "        [ 0.8860, -0.6262]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.decoder.W.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.decoder.W.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1634, -1.1773],\n",
      "        [ 0.3227, -1.2502]])\n"
     ]
    }
   ],
   "source": [
    "print(true_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
