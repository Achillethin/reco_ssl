{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49af45a4-2a71-433c-a4e9-2f55ecabf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import MultiVAE, Multi_our_VAE, SimCLR_reco_model, BYOL_reco_model\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from rezende_plot import run_rezende\n",
    "from training import train_model, train_met_model, train_simclr_model, train_byol_model\n",
    "\n",
    "from args import get_args\n",
    "from data import Dataset\n",
    "\n",
    "from metrics import NDCG_binary_at_k_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df9e7a1b-65a7-4ab7-b707-6f490934c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "        \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "        __getattr__ = dict.get\n",
    "        __setattr__ = dict.__setitem__\n",
    "        __delattr__ = dict.__delitem__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7277333a-4e54-47b2-819d-74ac03a863a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "args = dotdict(args)\n",
    "args['data'] = 'foursquare' #'gowalla'\n",
    "\n",
    "args['model'] = 'BYOL_reco_model' #SimCLR_reco_model, MultiVAE, BYOL_reco_model\n",
    "\n",
    "args['n_epoches'] = 100\n",
    "\n",
    "args['n_epoches_dec'] = 50\n",
    "\n",
    "args['lrdec'] = 1e-3\n",
    "\n",
    "args['lrenc'] = 1e-3\n",
    "\n",
    "args['train_batch_size'] = 500\n",
    "\n",
    "args['val_batch_size'] = 200\n",
    "\n",
    "args['n_val_samples'] = 1\n",
    "\n",
    "args['annealing'] = True\n",
    "\n",
    "args.total_anneal_steps = 50\n",
    "\n",
    "args.anneal_cap = 1.\n",
    "\n",
    "args.print_info_ = 5\n",
    "\n",
    "args.metric = NDCG_binary_at_k_batch\n",
    "\n",
    "args.device = 'cpu'\n",
    "\n",
    "args.n_views = 2\n",
    "\n",
    "args.temperature = .07\n",
    "\n",
    "args.dropout_rate = 0.83\n",
    "\n",
    "args.criterion_dec = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "args.m = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3f518b-7ab7-47f3-8ba9-ed81972f61ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m  0.995\n",
      "Sequential(\n",
      "  (0): Linear(in_features=26150, out_features=600, bias=True)\n",
      "  (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Tanh()\n",
      "  (3): Linear(in_features=600, out_features=100, bias=True)\n",
      ")\n",
      "Sequential(\n",
      "  (0): Linear(in_features=100, out_features=600, bias=True)\n",
      "  (1): BatchNorm1d(600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): Tanh()\n",
      "  (3): Linear(in_features=600, out_features=26150, bias=True)\n",
      ")\n",
      "Epoch  0 Loss  tensor(2.5159, grad_fn=<MeanBackward0>)\n",
      "Epoch  1 Loss  tensor(1.6024, grad_fn=<MeanBackward0>)\n",
      "Epoch  2 Loss  tensor(1.1275, grad_fn=<MeanBackward0>)\n",
      "Epoch  3 Loss  tensor(0.8507, grad_fn=<MeanBackward0>)\n",
      "Epoch  4 Loss  tensor(1.0303, grad_fn=<MeanBackward0>)\n",
      "Epoch  5 Loss  tensor(0.7929, grad_fn=<MeanBackward0>)\n",
      "Epoch  6 Loss  tensor(0.7482, grad_fn=<MeanBackward0>)\n",
      "Epoch  7 Loss  tensor(0.7549, grad_fn=<MeanBackward0>)\n",
      "Epoch  8 Loss  tensor(0.7558, grad_fn=<MeanBackward0>)\n",
      "Epoch  9 Loss  tensor(0.7153, grad_fn=<MeanBackward0>)\n",
      "Epoch  10 Loss  tensor(0.6218, grad_fn=<MeanBackward0>)\n",
      "Epoch  11 Loss  tensor(0.5817, grad_fn=<MeanBackward0>)\n",
      "Epoch  12 Loss  tensor(0.6439, grad_fn=<MeanBackward0>)\n",
      "Epoch  13 Loss  tensor(0.5660, grad_fn=<MeanBackward0>)\n",
      "Epoch  14 Loss  tensor(0.5884, grad_fn=<MeanBackward0>)\n",
      "Epoch  15 Loss  tensor(0.6091, grad_fn=<MeanBackward0>)\n",
      "Epoch  16 Loss  tensor(0.5389, grad_fn=<MeanBackward0>)\n",
      "Epoch  17 Loss  tensor(0.6105, grad_fn=<MeanBackward0>)\n",
      "Epoch  18 Loss  tensor(0.5517, grad_fn=<MeanBackward0>)\n",
      "Epoch  19 Loss  tensor(0.5632, grad_fn=<MeanBackward0>)\n",
      "Epoch  20 Loss  tensor(0.5226, grad_fn=<MeanBackward0>)\n",
      "Epoch  21 Loss  tensor(0.6747, grad_fn=<MeanBackward0>)\n",
      "Epoch  22 Loss  tensor(0.4784, grad_fn=<MeanBackward0>)\n",
      "Epoch  23 Loss  tensor(0.5427, grad_fn=<MeanBackward0>)\n",
      "Epoch  24 Loss  tensor(0.5801, grad_fn=<MeanBackward0>)\n",
      "Epoch  25 Loss  tensor(0.4931, grad_fn=<MeanBackward0>)\n",
      "Epoch  26 Loss  tensor(0.5137, grad_fn=<MeanBackward0>)\n",
      "Epoch  27 Loss  tensor(0.5536, grad_fn=<MeanBackward0>)\n",
      "Epoch  28 Loss  tensor(0.5568, grad_fn=<MeanBackward0>)\n",
      "Epoch  29 Loss  tensor(0.5836, grad_fn=<MeanBackward0>)\n",
      "Epoch  30 Loss  tensor(0.5411, grad_fn=<MeanBackward0>)\n",
      "Epoch  31 Loss  tensor(0.5961, grad_fn=<MeanBackward0>)\n",
      "Epoch  32 Loss  tensor(0.5064, grad_fn=<MeanBackward0>)\n",
      "Epoch  33 Loss  tensor(0.4576, grad_fn=<MeanBackward0>)\n",
      "Epoch  34 Loss  tensor(0.5765, grad_fn=<MeanBackward0>)\n",
      "Epoch  35 Loss  tensor(0.5399, grad_fn=<MeanBackward0>)\n",
      "Epoch  36 Loss  tensor(0.5592, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)\n",
    "elif args.model == 'BYOL_reco_model':\n",
    "    model = BYOL_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_byol_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274320d4-c499-4441-9566-4ddd49830e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "args = dotdict(args)\n",
    "args['data'] = 'foursquare' #'gowalla'\n",
    "\n",
    "args['model'] = 'MultiVAE' #SimCLR_reco_model, MultiVAE\n",
    "\n",
    "args['n_epoches'] = 10\n",
    "\n",
    "args['n_epoches_dec'] = 50\n",
    "\n",
    "args['lrdec'] = 1e-3\n",
    "\n",
    "args['lrenc'] = 1e-3\n",
    "\n",
    "args['train_batch_size'] = 500\n",
    "\n",
    "args['val_batch_size'] = 200\n",
    "\n",
    "args['n_val_samples'] = 1\n",
    "\n",
    "args['annealing'] = True\n",
    "\n",
    "args.total_anneal_steps = 50\n",
    "\n",
    "args.anneal_cap = 1.\n",
    "\n",
    "args.print_info_ = 5\n",
    "\n",
    "args.metric = NDCG_binary_at_k_batch\n",
    "\n",
    "args.device = 'cpu'\n",
    "\n",
    "args.n_views = 2\n",
    "\n",
    "args.temperature = .07\n",
    "\n",
    "args.dropout_rate = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bdcc54-dca4-4807-b366-7d37dc650e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values_vae = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)\n",
    "elif args.model = 'BYOL_reco_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d315b-6727-4c65-957d-2f534377ab9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293acae-90c0-4535-9b6e-c623bca5e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "\n",
    "args = dotdict(args)\n",
    "args['data'] = 'foursquare' #'gowalla'\n",
    "\n",
    "args['model'] = 'SimCLR_reco_model' #SimCLR_reco_model, MultiVAE\n",
    "\n",
    "args['n_epoches'] = 100\n",
    "\n",
    "args['n_epoches_dec'] = 50\n",
    "\n",
    "args['lrdec'] = 1e-3\n",
    "\n",
    "args['lrenc'] = 1e-3\n",
    "\n",
    "args['train_batch_size'] = 500\n",
    "\n",
    "args['val_batch_size'] = 200\n",
    "\n",
    "args['n_val_samples'] = 1\n",
    "\n",
    "args['annealing'] = True\n",
    "\n",
    "args.total_anneal_steps = 50\n",
    "\n",
    "args.anneal_cap = 1.\n",
    "\n",
    "args.print_info_ = 5\n",
    "\n",
    "args.metric = NDCG_binary_at_k_batch\n",
    "\n",
    "args.device = 'cpu'\n",
    "\n",
    "args.n_views = 2\n",
    "\n",
    "args.temperature = .07\n",
    "\n",
    "args.dropout_rate = 0.8\n",
    "\n",
    "args.criterion_dec = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2510e44b-f089-4c38-af07-7eb108e2402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef0e523-d4b9-424a-aa09-9476f6221601",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dropout_rate = 0.8\n",
    "\n",
    "args.temperature = .3\n",
    "\n",
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f234965d-bf60-4d75-98ed-30c9b4946477",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.temperature = .1\n",
    "\n",
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68c416-cfa9-44d6-877f-e3331e01e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dropout_rate = 0.75\n",
    "\n",
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246c940-7ae1-441f-b9a1-2bcf8178c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dropout_rate = 0.4\n",
    "\n",
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959b83c-8bf1-4f21-abab-7bf5bec38f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.dropout_rate = 0.83\n",
    "\n",
    "dataset = Dataset(args)\n",
    "# pdb.set_trace()\n",
    "layers = [100, 600, dataset.n_items]\n",
    "args.z_dim = layers[0]\n",
    "args.l2_coeff = 0.\n",
    "# with torch.autograd.detect_anomaly():\n",
    "if args.model == 'MultiVAE':\n",
    "    model = MultiVAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_model(model, dataset, args)\n",
    "elif args.model == 'Multi_our_VAE':\n",
    "    model = Multi_our_VAE(layers, args=args).to(args.device)\n",
    "    metric_values = train_met_model(model, dataset, args)\n",
    "elif args.model == 'SimCLR_reco_model':\n",
    "    model = SimCLR_reco_model(args=args, p_dims=layers).to(args.device)\n",
    "    metric_values = train_simclr_model(model, dataset, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4970748-5a04-438e-a927-6a611d7cec5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
